id: spotify_ingestion  
namespace: spotify_pipeline
description: "Automated pipeline: Download Spotify dataset from Kaggle, preprocess it, upload to GCS, and load into BigQuery."

tasks:
  - id: download_spotify_dataset
    type: "io.kestra.plugin.scripts.shell.Commands"
    description: "Download the latest Spotify dataset from Kaggle."
    containerImage: "python:3.9"
    outputFiles:
      - "universal_top_spotify_songs.csv"
    env:
      KAGGLE_CONFIG_DIR: "/root/.kaggle"
    beforeCommands:
      - "pip install --no-cache-dir kaggle"
    commands:
      - "mkdir -p $KAGGLE_CONFIG_DIR"
      - "echo '{{ kv('KAGGLE_JSON') | toJson }}' > $KAGGLE_CONFIG_DIR/kaggle.json"
      - "chmod 600 $KAGGLE_CONFIG_DIR/kaggle.json"
      - "kaggle datasets download -d asaniczka/top-spotify-songs-in-73-countries-daily-updated -p ./ --force"
      - "unzip -o ./top-spotify-songs-in-73-countries-daily-updated.zip -d ./"
      - "ls -lh ./"
      - "[ -f ./universal_top_spotify_songs.csv ] && echo '✅ File exists!' || { echo '❌ ERROR: File not found!'; exit 1; }"

  - id: preprocess_csv
    type: "io.kestra.plugin.scripts.python.Commands"
    description: "Preprocess CSV to ensure empty values are recognized as NULL by BigQuery."
    containerImage: "python:3.9"
    outputFiles:
      - "cleaned_spotify_songs.csv.gz"
    beforeCommands:
      - "pip install pandas"
    commands:
      - |
        python - <<EOF
        import os
        import pandas as pd

        csv_file = "{{ outputs.download_spotify_dataset.outputFiles['universal_top_spotify_songs.csv'] }}"
        if not os.path.exists(csv_file):
            raise FileNotFoundError(f"❌ ERROR: {csv_file} not found!")
        
        print(f"✅ Found CSV file: {csv_file}")

        # Load CSV with proper encoding
        df = pd.read_csv(csv_file, encoding='utf-8')

        # Standardize empty values to NULL (handles spaces, tabs, and invisible characters)
        df = df.map(lambda x: None if isinstance(x, str) and x.strip() == "" else x)

        # Drop rows with missing required values
        required_columns = ["name", "spotify_id"]
        df.dropna(subset=required_columns, inplace=True)

        # Save as compressed CSV
        output_file = "cleaned_spotify_songs.csv.gz"
        df.to_csv(output_file, index=False, encoding='utf-8-sig', compression='gzip')

        print(f"✅ Processed CSV saved as: {output_file}")
        EOF

  - id: upload_to_gcs
    type: "io.kestra.plugin.scripts.shell.Commands"
    description: "Upload the cleaned dataset to Google Cloud Storage."
    containerImage: "google/cloud-sdk:latest"
    env:
      GOOGLE_APPLICATION_CREDENTIALS: "/tmp/gcp-key.json"
    commands:
      - "echo '{{ kv('GCP_SERVICE_ACCOUNT_BASE64') }}' | base64 -d > $GOOGLE_APPLICATION_CREDENTIALS"
      - "chmod 600 $GOOGLE_APPLICATION_CREDENTIALS"
      - "gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS"
      - "gcloud auth list"
      - "FILE_PATH={{ outputs.preprocess_csv.outputFiles['cleaned_spotify_songs.csv.gz'] }}"
      - "ls -lh $FILE_PATH || { echo '❌ ERROR: File not found!'; exit 1; }"
      - "gsutil -o 'GSUtil:parallel_composite_upload_threshold=100M' -h 'Content-Type:text/csv' -h 'Content-Encoding:gzip' cp $FILE_PATH gs://spotify_radu_bucket/raw_data/cleaned_spotify_songs.csv.gz"
      - "echo '✅ Upload complete!'"

  - id: load_to_bigquery
    type: io.kestra.plugin.gcp.bigquery.LoadFromGcs
    description: "Load the cleaned dataset into BigQuery."
    serviceAccount: "{{ kv('GCP_SERVICE_ACCOUNT') }}"
    projectId: "spotify-sandbox-453505"
    from:
      - "gs://spotify_radu_bucket/raw_data/cleaned_spotify_songs.csv.gz"
    destinationTable: "spotify-sandbox-453505.spotify_radu_dataset.spotify_top_songs"
    format: CSV
    csvOptions:
      skipLeadingRows: 1
      allowJaggedRows: true
      encoding: UTF-8
      fieldDelimiter: ","
      quote: '"'
    writeDisposition: WRITE_TRUNCATE
    schema:
      fields:
        - name: spotify_id
          type: STRING
          mode: REQUIRED
        - name: name
          type: STRING
          mode: REQUIRED
        - name: artists
          type: STRING
          mode: REQUIRED
        - name: daily_rank
          type: INT64
          mode: REQUIRED
        - name: daily_movement
          type: INT64
          mode: NULLABLE
        - name: weekly_movement
          type: INT64
          mode: NULLABLE
        - name: country
          type: STRING
          mode: NULLABLE
        - name: snapshot_date
          type: DATE
          mode: REQUIRED
        - name: popularity
          type: INT64
          mode: NULLABLE
        - name: is_explicit
          type: BOOL
          mode: NULLABLE
        - name: duration_ms
          type: INT64
          mode: NULLABLE
        - name: album_name
          type: STRING
          mode: NULLABLE
        - name: album_release_date
          type: DATE
          mode: NULLABLE
        - name: danceability
          type: FLOAT64
          mode: NULLABLE
        - name: energy
          type: FLOAT64
          mode: NULLABLE
        - name: key
          type: INT64
          mode: NULLABLE
        - name: loudness
          type: FLOAT64
          mode: NULLABLE
        - name: mode
          type: INT64
          mode: NULLABLE
        - name: speechiness
          type: FLOAT64
          mode: NULLABLE
        - name: acousticness
          type: FLOAT64
          mode: NULLABLE
        - name: instrumentalness
          type: FLOAT64
          mode: NULLABLE
        - name: liveness
          type: FLOAT64
          mode: NULLABLE
        - name: valence
          type: FLOAT64
          mode: NULLABLE
        - name: tempo
          type: FLOAT64
          mode: NULLABLE
        - name: time_signature
          type: INT64
          mode: NULLABLE
    autodetect: false

triggers:
  - id: daily_schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: "0 0 * * *"